library(ElemStatLearn)
data(prostate)
str(prostate)
small <- prostate[1:5,]
lm(lpsa ~ ., data = small)
library(ISLR)
data(wage)
library(ggplot2)
library(caret)
Wage <- subset(Wage, select = c(logwage))
data(wage)
rm(list=ls())
data(wage)
library(ggplot2)
Wage <- subset(Wage, select = c(logwage))
Wage <- subset(Wage, select = c(-logwage))
rm(list=ls())
Wage <- subset(Wage, select = c(-logwage))
inBuild <- createDataPartition(y = Wage$wage)
validation <- Wage[inBuild,]
validation <- Wage[-inBuild,]
inBuild <- createDataPartition(y = Wage$wage,
p = 0.7, list = FALSE)
validation <- Wage[-inBuild,]
buildData <- Wage[inBuild,]
inTrain <- createDataPartition(y = buildData$wage,
p = 0.7, list = FALSE)
training <- buildData[inTrain,]
testing <- buildData[-inTrain]
dim(training)
data(Wage)
Wage <- subset(Wage, select = c(-logwage)) # Remove because it would be a good predictor
data(Wage)
Wage <- subset(Wage, select = -c(logwage)) # Remove because it would be a good predictor
inBuild <- createDataPartition(y = Wage$wage,
p = 0.7, list = FALSE)
validation <- Wage[-inBuild,]
buildData <- Wage[inBuild,]
inTrain <- createDataPartition(y = buildData$wage,
p = 0.7, list = FALSE)
training <- buildData[inTrain,]
testing <- buildData[-inTrain]
dim(training)
dim(testing)
data(Wage)
Wage <- subset(Wage, select = -c(logwage)) # Remove because it would be a good predictor
inBuild <- createDataPartition(y = Wage$wage,
p = 0.7, list = FALSE)
validation <- Wage[-inBuild,]
buildData <- Wage[inBuild,]
inTrain <- createDataPartition(y = buildData$wage,
p = 0.7, list = FALSE)
training <- buildData[inTrain,]
testing <- buildData[-inTrain]
dim(training)
dim(testing)
dim(validation)
testing <- buildData[-inTrain,]
mod1 <- train(wage ~ ., method = "glm", data = training)
mod1 <- train(wage ~ ., method = "rf", data = training,
trControl = trainControl(method = "cv"), number = 3)
mod1 <- train(wage ~ ., method = "glm", data = training)
mod1 <- train(wage ~ ., method = "glm", data = training)
warnings()
mod1 <- train(wage ~ ., method = "glm", data = training)
mod2 <- train(wage ~ ., method = "rf", data = training,
trControl = trainControl(method = "cv"), number = 3)
rm(list=ls())
library(quantmod)
#===================
# Lecture 3
#===============
install.packages("quantmod")
library(quantmod)
from.dat <- as.Date("01/01/08", format = "%m/%d/%y")
to.dat <- as.Date("12/31/13", format = "%m/%d/%y")
getSymbols("GOOG", src = "google", from = from.dat, to.dat)
getSymbols("GOOG", src = "google", from = from.dat, to.dat)
library(dplyr)
getSymbols("GOOG", src = "google", from = from.dat, to.dat)
getSymbols("GOOG", src = "google", from = from.dat, to = to.dat)
getSymbols("GOOG", src = "yahoo", from = from.dat, to = to.dat)
head("GOOG")
rm(list=ls())
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
View(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod1 <- lm(y ~., method = "rf", data = vowel.train)
mod1 <- train(y ~.,
method = "rf",
data = vowel.train)
mod2 <- train(y ~.,
method = "gbm",
data = vowel.train)
pred1 <- predict(mod1, vowel.test)
pred2 <- predict(mod2, vowel.test)
qplot(pred1, pred2, colour = y, data = vowel.test)
summary(pred1)
summary(mod1)
summarise(pred1)
# Extract accuracies
confusionMatrix(pred_rf, vowel.test$y)$overall
# Extract accuracies
confusionMatrix(pred1, vowel.test$y)$overall
# Extract accuracies
View(confusionMatrix(pred1, vowel.test$y)$overall)
View(confusionMatrix(pred2, vowel.test$y)$overall)
predDF <- data.frame(pred1, pred2, y = vowel.test$y)
# Accuracy among the test set samples where the two methods agree
sum(pred1[predDF$pred1 == predDF$pred2] ==
predDF$y[predDF$pred1 == predDF$pred2]) /
sum(predDF$pred1 == predDF$pred2)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
rm(list=ls())
data(AlzheimerDisease)
adData <-  data.frame(diagnosis,predictors)
View(adData)
inTrain <-  createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training <-  adData[ inTrain,]
testing <-  adData[-inTrain,]
set.seed(62433)
set.seed(3433)
data(AlzheimerDisease)
adData <-  data.frame(diagnosis,predictors)
View(adData)
inTrain <-  createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training <-  adData[ inTrain,]
testing <-  adData[-inTrain,]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., method = "rf", data = training)
mod_gbm <-train(diagnosis ~ ., method = "gbm", data = training)
mod_lda <- train(diagnosis ~ ., method = "lda", data = training)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
sqrt(sum((pred_rf - testing$diagnosis)^2))
sqrt(sum((pred_gbm - testing$diagnosis)^2))
sqrt(sum((pred_lda - testing$diagnosis)^2))
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
confusionMatrix(combPred, testing$diagnosis)$overall[1]
rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
mod_lasso <- train(CompressiveStrength ~ .,
data = training, method = "lasso")
library(elasticnet)
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
RM(LIST=LS())
rm(list=ls())
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
dat = read.csv("~/Desktop/gaData.csv")
dat = read.csv("~/Desktop/gaData.csv")
library(readr)
gaData <- read_csv("gaData.csv")
View(gaData)
training = dat[year(dat$date) < 2012,]
dat <- gaData
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
install.packages("forecast")
library(forecast)
mod_ts <- bats(tstrain)
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) /
dim(testing)[1]
rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
